# å¤šæ¨¡æ€æŠ‘éƒæ£€æµ‹ï¼šä»Baselineåˆ°é«˜é˜¶æ·±åº¦å­¦ä¹ æ–¹æ³•çš„å®ç°è®¡åˆ’

## é¡¹ç›®èƒŒæ™¯

**å½“å‰çŠ¶æ€ï¼š**
- âœ… Phase 1: æ•°æ®é¢„å¤„ç†å®Œæˆï¼ˆ46ä¸ªç”¨æˆ·ï¼Œ4ä¸ªé˜³æ€§æ ·æœ¬ï¼‰
- âœ… Phase 2: ç‰¹å¾å·¥ç¨‹å®Œæˆï¼ˆ44ä¸ªç‰¹å¾ä»GPSã€Appã€é€šä¿¡ã€æ´»åŠ¨4ä¸ªæ¨¡æ€ï¼‰
- âŒ Phase 3-4: Baselineå»ºæ¨¡æœªå¼€å§‹
- âŒ Phase 5-6: é«˜é˜¶æ–¹æ³•å’Œå¯è§£é‡Šæ€§æœªå¼€å§‹

**ç”¨æˆ·éœ€æ±‚ï¼š**
1. ä¿ç•™ä¼ ç»ŸML baselineï¼ˆé€»è¾‘å›å½’ã€éšæœºæ£®æ—ã€XGBoostï¼‰ä½œä¸ºå¯¹æ¯”
2. æ·»åŠ 4ç§é«˜é˜¶æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼šVAEã€GNNã€å¯¹æ¯”å­¦ä¹ ã€Transformer
3. é‡ç‚¹å…³æ³¨ç‰¹å¾å­¦ä¹ ä¸è¡¨ç¤ºï¼ˆè€Œéä»…åˆ†ç±»æ€§èƒ½ï¼‰
4. ä½¿ç”¨MacBook MPSåŠ é€Ÿï¼ˆmambaç¯å¢ƒï¼š`qbio`ï¼‰

**æ ¸å¿ƒæŒ‘æˆ˜ï¼š**
- ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡ï¼š4ä¸ªé˜³æ€§ vs 42ä¸ªé˜´æ€§ï¼ˆ10.5:1ï¼‰
- å°æ ·æœ¬é‡ï¼ˆn=46ï¼‰å®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆ
- éœ€è¦å¯è§£é‡Šæ€§æ¥å‘ç°æ•°å­—ç”Ÿç‰©æ ‡è®°

---

## å®æ–½è·¯çº¿å›¾ï¼ˆ7ä¸ªé˜¶æ®µï¼‰

### Phase 3: Baselineæ¨¡å‹ï¼ˆä¼ ç»ŸMLï¼‰

**ç›®æ ‡ï¼š** å»ºç«‹æ€§èƒ½åŸºå‡†ï¼ŒéªŒè¯ç‰¹å¾æœ‰æ•ˆæ€§

#### 3.1 åˆ›å»ºæ¨¡å‹åŸºç¡€è®¾æ–½

**æ–°å»ºæ–‡ä»¶ï¼š**

1. **`src/models/baseline.py`** - Baselineæ¨¡å‹å°è£…
   ```python
   class BaselineModel:
       - LogisticRegression (L2æ­£åˆ™åŒ–, balanced class weights)
       - RandomForest (max_depth=3, n_estimators=500, balanced)
       - XGBoost (scale_pos_weight=10.5 for imbalance)
   ```

2. **`src/models/evaluation.py`** - è¯„ä¼°æŒ‡æ ‡å’Œäº¤å‰éªŒè¯
   ```python
   - stratified_cv(): 5æŠ˜åˆ†å±‚äº¤å‰éªŒè¯
   - evaluate_model(): AUC-ROC, PR-AUC, sensitivity, specificity, F1
   - permutation_test(): ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆp<0.05ï¼‰
   - plot_roc_curve(), plot_confusion_matrix()
   ```

3. **`src/utils/data_loader.py`** - æ•°æ®åŠ è½½å·¥å…·
   ```python
   - load_features_labels(): åŠ è½½combined_features.parquet + item9_labels_pre.csv
   - train_test_split_stratified(): ä¿æŒç±»åˆ«æ¯”ä¾‹
   - apply_feature_scaling(): StandardScaler for continuous features
   ```

4. **`scripts/07_train_baseline.py`** - è®­ç»ƒè„šæœ¬
   ```bash
   # ä½¿ç”¨æ–¹å¼
   mamba activate qbio
   python scripts/07_train_baseline.py
   ```

5. **`notebooks/03_baseline_modeling.ipynb`** - äº¤äº’å¼åˆ†æ

**è¾“å‡ºï¼š**
- `results/models/logistic_baseline.pkl`
- `results/models/random_forest_baseline.pkl`
- `results/models/xgboost_baseline.pkl`
- `results/metrics/baseline_metrics.json`
- `results/figures/baseline_roc_curves.png`
- `results/figures/feature_importance_comparison.png`

**é¢„æœŸæ€§èƒ½ï¼š**
- AUC-ROC: 0.60-0.70ï¼ˆåŸºäºæ–‡çŒ®Saeb et al. 2015ï¼‰
- Sensitivity â‰¥ 0.80ï¼ˆä¸´åºŠä¼˜å…ˆçº§ï¼šä¸é—æ¼é˜³æ€§æ¡ˆä¾‹ï¼‰
- è¯†åˆ«top 5-10ä¸ªé¢„æµ‹ç‰¹å¾

---

### Phase 4: æ·±åº¦å­¦ä¹ åŸºç¡€è®¾æ–½

**ç›®æ ‡ï¼š** é…ç½®PyTorch + MPSï¼Œå»ºç«‹è®­ç»ƒæ¡†æ¶

#### 4.1 ç¯å¢ƒé…ç½®

**æ›´æ–° `requirements.txt`ï¼š**
```txt
# å–æ¶ˆæ³¨é‡Šå¹¶æ›´æ–°PyTorchç‰ˆæœ¬ï¼ˆæ”¯æŒApple Silicon MPSï¼‰
torch>=2.0.0
torchvision>=0.15.0
torch-geometric>=2.3.0  # For GNN
pytorch-metric-learning>=2.0.0  # For contrastive learning
```

**å®‰è£…å‘½ä»¤ï¼š**
```bash
mamba activate qbio
mamba install pytorch torchvision -c pytorch  # è‡ªåŠ¨å¯ç”¨MPS
pip install torch-geometric pytorch-metric-learning
```

#### 4.2 PyTorchè®­ç»ƒåŸºç¡€è®¾æ–½

**æ–°å»ºæ–‡ä»¶ï¼š**

1. **`src/models/pytorch_base.py`** - PyTorchåŸºç±»
   ```python
   class BaseDeepModel(nn.Module):
       - MPS deviceé…ç½®: device = "mps" if torch.backends.mps.is_available()
       - é€šç”¨è®­ç»ƒå¾ªç¯: train(), validate(), test()
       - Early stopping (patience=20)
       - Model checkpointing (ä¿å­˜æœ€ä½³æ¨¡å‹)
       - Reproducibility (torch.manual_seed(42))
   ```

2. **`src/utils/pytorch_utils.py`** - PyTorchå·¥å…·
   ```python
   - TabularDataset(Dataset): åŒ…è£…44ç»´ç‰¹å¾ + æ ‡ç­¾
   - get_dataloaders(): åˆ›å»ºtrain/val/test DataLoader
   - set_seed(): å›ºå®šéšæœºç§å­
   - count_parameters(): è®¡ç®—æ¨¡å‹å‚æ•°é‡
   ```

3. **`configs/model_configs.yaml`** - è¶…å‚æ•°é…ç½®ï¼ˆæ–°å»ºæ–‡ä»¶ï¼‰
   ```yaml
   common:
     batch_size: 16  # å°æ‰¹é‡é¿å…è¿‡æ‹Ÿåˆ
     learning_rate: 0.001
     weight_decay: 0.01  # L2æ­£åˆ™åŒ–
     max_epochs: 200
     early_stopping_patience: 20
     random_seed: 42

   vae:
     latent_dim: 8
     hidden_dims: [32, 16]
     beta: 1.0  # KLæƒé‡

   gnn:
     hidden_channels: 16
     num_layers: 2
     dropout: 0.3
     k_neighbors: 5  # KNNæ„å›¾

   contrastive:
     temperature: 0.5
     projection_dim: 32
     augmentation_strength: 0.2

   transformer:
     d_model: 16
     nhead: 4
     num_layers: 2
     dropout: 0.2
   ```

---

### Phase 5A: Variational Autoencoder (VAE)

**ç›®æ ‡ï¼š** å­¦ä¹ 44ç»´ç‰¹å¾çš„ä½ç»´æ½œåœ¨è¡¨ç¤ºï¼Œç”¨äºå¼‚å¸¸æ£€æµ‹å’Œæ•°æ®å¢å¼º

#### 5A.1 æ¨¡å‹æ¶æ„

**æ–°å»ºæ–‡ä»¶ï¼š`src/models/vae_model.py`**

```python
class MultimodalVAE(BaseDeepModel):
    def __init__(self, input_dim=44, latent_dim=8, hidden_dims=[32, 16]):
        """
        Encoder: 44 -> 32 -> 16 -> latent_dim*2 (mean + logvar)
        Decoder: latent_dim -> 16 -> 32 -> 44
        """
        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(44, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 16),
            nn.BatchNorm1d(16),
            nn.ReLU()
        )
        self.fc_mean = nn.Linear(16, latent_dim)
        self.fc_logvar = nn.Linear(16, latent_dim)

        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 16),
            nn.ReLU(),
            nn.Linear(16, 32),
            nn.ReLU(),
            nn.Linear(32, 44)
        )

    def loss_function(self, recon_x, x, mean, logvar, beta=1.0):
        """VAE Loss = Reconstruction + beta * KL divergence"""
        MSE = F.mse_loss(recon_x, x, reduction='sum')
        KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())
        return MSE + beta * KLD
```

#### 5A.2 åº”ç”¨åœºæ™¯

**1. å¼‚å¸¸æ£€æµ‹ï¼ˆAnomaly Detectionï¼‰**
- è®¡ç®—é‡æ„è¯¯å·®ï¼š`||x - decoder(encoder(x))||^2`
- å‡è®¾ï¼šæŠ‘éƒç—‡æ‚£è€…ï¼ˆé˜³æ€§æ ·æœ¬ï¼‰æœ‰æ›´é«˜çš„é‡æ„è¯¯å·®
- é˜ˆå€¼åˆ†ç±»ï¼šé‡æ„è¯¯å·® > threshold â†’ é¢„æµ‹ä¸ºé˜³æ€§

**2. æ•°æ®å¢å¼ºï¼ˆè§£å†³ç±»åˆ«ä¸å¹³è¡¡ï¼‰**
- ä»4ä¸ªé˜³æ€§æ ·æœ¬çš„æ½œåœ¨åˆ†å¸ƒä¸­é‡‡æ ·ç”Ÿæˆåˆæˆæ ·æœ¬
- `z ~ N(mean_positive, var_positive)`
- `x_synthetic = decoder(z)`
- ç”Ÿæˆ20-30ä¸ªåˆæˆé˜³æ€§æ ·æœ¬ç”¨äºè®­ç»ƒbaseline

**3. å¯è§†åŒ–æ½œåœ¨ç©ºé—´**
- t-SNE/UMAPå¯è§†åŒ–8ç»´æ½œåœ¨å‘é‡
- æ£€æŸ¥é˜³æ€§/é˜´æ€§æ ·æœ¬æ˜¯å¦åœ¨æ½œåœ¨ç©ºé—´ä¸­å¯åˆ†

**æ–°å»ºæ–‡ä»¶ï¼š**
- `scripts/08_train_vae.py` - VAEè®­ç»ƒè„šæœ¬
- `notebooks/04_vae_analysis.ipynb` - æ½œåœ¨ç©ºé—´å¯è§†åŒ–

**è¾“å‡ºï¼š**
- `results/models/vae_best.pth`
- `results/figures/vae_latent_space.png` (t-SNE)
- `results/figures/vae_reconstruction_error.png`
- `data/processed/features/vae_synthetic_samples.parquet` (å¢å¼ºæ•°æ®)

---

### Phase 5B: Graph Neural Network (GNN)

**ç›®æ ‡ï¼š** åˆ©ç”¨ç”¨æˆ·ç›¸ä¼¼æ€§å›¾ç»“æ„è¿›è¡ŒåŠç›‘ç£å­¦ä¹ 

#### 5B.1 å›¾æ„å»ºç­–ç•¥

**æ–°å»ºæ–‡ä»¶ï¼š`src/features/graph_builder.py`**

```python
class UserSimilarityGraph:
    def build_knn_graph(features, k=5, metric='cosine'):
        """
        åŸºäºç‰¹å¾ç›¸ä¼¼åº¦æ„å»ºKè¿‘é‚»å›¾
        - èŠ‚ç‚¹ï¼š46ä¸ªç”¨æˆ·
        - è¾¹ï¼šè¿æ¥kä¸ªæœ€ç›¸ä¼¼ç”¨æˆ·ï¼ˆåŸºäº44ç»´ç‰¹å¾ä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        - è¾¹æƒé‡ï¼šç›¸ä¼¼åº¦åˆ†æ•°
        """
        from sklearn.neighbors import kneighbors_graph
        A = kneighbors_graph(features, k, metric=metric, include_self=False)
        return A  # é‚»æ¥çŸ©é˜µ
```

**å›¾ç»Ÿè®¡ï¼š**
- èŠ‚ç‚¹æ•°ï¼š46
- è¾¹æ•°ï¼šçº¦ 46 * 5 = 230ï¼ˆk=5ï¼‰
- èŠ‚ç‚¹ç‰¹å¾ï¼š44ç»´åŸå§‹ç‰¹å¾
- èŠ‚ç‚¹æ ‡ç­¾ï¼š4ä¸ªé˜³æ€§ï¼ˆæœ‰ç›‘ç£ï¼‰+ 42ä¸ªé˜´æ€§

#### 5B.2 GNNæ¶æ„

**æ–°å»ºæ–‡ä»¶ï¼š`src/models/gnn_model.py`**

```python
from torch_geometric.nn import GCNConv, GATConv

class DepGraphNet(BaseDeepModel):
    """Graph Attention Network for depression prediction"""

    def __init__(self, in_channels=44, hidden_channels=16, num_layers=2):
        # ä½¿ç”¨GATè€ŒéGCNï¼Œå› ä¸ºattentionå¯è§£é‡Šæ€§æ›´å¼º
        self.conv1 = GATConv(in_channels, hidden_channels, heads=4, dropout=0.3)
        self.conv2 = GATConv(hidden_channels*4, hidden_channels, heads=1, dropout=0.3)
        self.classifier = nn.Linear(hidden_channels, 2)  # äºŒåˆ†ç±»

    def forward(self, x, edge_index):
        # x: [46, 44] èŠ‚ç‚¹ç‰¹å¾
        # edge_index: [2, num_edges] è¾¹è¿æ¥
        x = self.conv1(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=0.3, training=self.training)
        x = self.conv2(x, edge_index)
        x = F.elu(x)
        out = self.classifier(x)
        return out, x  # è¿”å›logitså’ŒèŠ‚ç‚¹åµŒå…¥
```

#### 5B.3 è®­ç»ƒç­–ç•¥

**åŠç›‘ç£å­¦ä¹ ï¼š**
- ä½¿ç”¨æ‰€æœ‰46ä¸ªèŠ‚ç‚¹çš„ç‰¹å¾
- ä»…ç”¨4ä¸ªé˜³æ€§ + éƒ¨åˆ†é˜´æ€§æ ·æœ¬çš„æ ‡ç­¾è®­ç»ƒï¼ˆæ¨¡æ‹Ÿæ ‡æ³¨æˆæœ¬ï¼‰
- å›¾å·ç§¯ä¼ æ’­ç›‘ç£ä¿¡å·åˆ°æœªæ ‡æ³¨èŠ‚ç‚¹

**äº¤å‰éªŒè¯ï¼š**
- Leave-One-Out CVï¼ˆn=46å¤ªå°ä¸é€‚åˆk-foldï¼‰
- æ¯æ¬¡ç•™ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºæµ‹è¯•ï¼Œå…¶ä½™è®­ç»ƒ

**æ–°å»ºæ–‡ä»¶ï¼š**
- `scripts/09_train_gnn.py`
- `notebooks/05_gnn_analysis.ipynb` - æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–

**è¾“å‡ºï¼š**
- `results/models/gnn_best.pth`
- `results/figures/gnn_attention_weights.png` (å“ªäº›ç”¨æˆ·è¿æ¥é‡è¦)
- `results/figures/gnn_node_embeddings.png` (t-SNEå¯è§†åŒ–)

---

### Phase 5C: å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰

**ç›®æ ‡ï¼š** åœ¨å°æ ·æœ¬åœºæ™¯ä¸‹å­¦ä¹ åˆ¤åˆ«æ€§è¡¨ç¤º

#### 5C.1 æ•°æ®å¢å¼ºç­–ç•¥ï¼ˆTabular Dataï¼‰

**æ–°å»ºæ–‡ä»¶ï¼š`src/utils/augmentation.py`**

```python
class TabularAugmentation:
    """è¡¨æ ¼æ•°æ®å¢å¼ºæ–¹æ³•"""

    @staticmethod
    def mixup(x1, x2, alpha=0.2):
        """Mixup: çº¿æ€§æ’å€¼ä¸¤ä¸ªæ ·æœ¬"""
        lam = np.random.beta(alpha, alpha)
        return lam * x1 + (1 - lam) * x2

    @staticmethod
    def gaussian_noise(x, std=0.1):
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        noise = torch.randn_like(x) * std
        return x + noise

    @staticmethod
    def feature_cutout(x, p=0.2):
        """éšæœºé®ç›–éƒ¨åˆ†ç‰¹å¾ï¼ˆç±»ä¼¼Dropoutï¼‰"""
        mask = torch.rand(x.shape) > p
        return x * mask
```

#### 5C.2 å¯¹æ¯”å­¦ä¹ æ¡†æ¶

**æ–°å»ºæ–‡ä»¶ï¼š`src/models/contrastive_model.py`**

```python
from pytorch_metric_learning import losses

class ContrastiveEncoder(BaseDeepModel):
    """SimCLR-style contrastive learning"""

    def __init__(self, input_dim=44, projection_dim=32):
        # Encoder
        self.encoder = nn.Sequential(
            nn.Linear(44, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32)
        )
        # Projection head (for contrastive learning)
        self.projector = nn.Sequential(
            nn.Linear(32, projection_dim),
            nn.ReLU(),
            nn.Linear(projection_dim, projection_dim)
        )

    def forward(self, x):
        h = self.encoder(x)  # è¡¨ç¤ºå‘é‡
        z = self.projector(h)  # æŠ•å½±å‘é‡ï¼ˆç”¨äºå¯¹æ¯”æŸå¤±ï¼‰
        return h, z
```

**æŸå¤±å‡½æ•°ï¼šNT-Xent (SimCLR)**
```python
def nt_xent_loss(z_i, z_j, temperature=0.5):
    """
    z_i, z_j: åŒä¸€æ ·æœ¬çš„ä¸¤ä¸ªå¢å¼ºè§†å›¾
    æ‹‰è¿‘æ­£æ ·æœ¬å¯¹ï¼Œæ¨å¼€è´Ÿæ ·æœ¬å¯¹
    """
    from pytorch_metric_learning.losses import NTXentLoss
    loss_fn = NTXentLoss(temperature=temperature)
    return loss_fn(z_i, z_j, labels)
```

#### 5C.3 è®­ç»ƒç­–ç•¥

**æ­£æ ·æœ¬å¯¹æ„å»ºï¼š**
- åŒä¸€ç”¨æˆ·çš„ä¸¤æ¬¡å¢å¼ºï¼š`(x_i, augment1(x_i), augment2(x_i))`
- é˜³æ€§æ ·æœ¬ä¹‹é—´çš„é…å¯¹ï¼ˆ4ä¸ªé˜³æ€§æ ·æœ¬å¯ç»„åˆï¼‰

**è´Ÿæ ·æœ¬å¯¹ï¼š**
- ä¸åŒç”¨æˆ·ä¹‹é—´ï¼ˆç‰¹åˆ«æ˜¯é˜³æ€§-é˜´æ€§å¯¹ï¼‰

**ä¸‹æ¸¸ä»»åŠ¡ï¼š**
- å†»ç»“encoderï¼Œåªè®­ç»ƒä¸€ä¸ªå°åˆ†ç±»å™¨
- å¯¹æ¯”ï¼šencoderè¡¨ç¤º vs åŸå§‹44ç»´ç‰¹å¾

**æ–°å»ºæ–‡ä»¶ï¼š**
- `scripts/10_train_contrastive.py`
- `notebooks/06_contrastive_analysis.ipynb`

**è¾“å‡ºï¼š**
- `results/models/contrastive_encoder.pth`
- `results/figures/contrastive_embeddings.png`
- `results/metrics/contrastive_downstream_performance.json`

---

### Phase 5D: Multimodal Transformer/Attention

**ç›®æ ‡ï¼š** å­¦ä¹ 4ä¸ªæ¨¡æ€ï¼ˆGPSã€Appã€é€šä¿¡ã€æ´»åŠ¨ï¼‰ä¹‹é—´çš„äº¤äº’

#### 5D.1 å¤šæ¨¡æ€ç‰¹å¾åˆ’åˆ†

**ç‰¹å¾åˆ†ç»„ï¼ˆä»44ç»´æ‹†åˆ†ä¸º4ä¸ªæ¨¡æ€ï¼‰ï¼š**
```python
# GPS features: 11ç»´
gps_features = features[:, 0:11]

# App usage features: 10ç»´
app_features = features[:, 11:21]

# Communication features: 11ç»´
comm_features = features[:, 21:32]

# Activity features: 12ç»´ (åŒ…å«9ä¸ªactivity + 3ä¸ªphone lock)
activity_features = features[:, 32:44]
```

#### 5D.2 Transformeræ¶æ„

**æ–°å»ºæ–‡ä»¶ï¼š`src/models/multimodal_transformer.py`**

```python
class MultimodalTransformer(BaseDeepModel):
    """
    å°†4ä¸ªæ¨¡æ€è§†ä¸º4ä¸ªtokenï¼Œä½¿ç”¨Transformerèåˆ
    """

    def __init__(self, modality_dims=[11, 10, 11, 12], d_model=16, nhead=4):
        # æ¨¡æ€åµŒå…¥å±‚ï¼ˆå°†ä¸åŒç»´åº¦æŠ•å½±åˆ°ç»Ÿä¸€ç»´åº¦ï¼‰
        self.modality_embeddings = nn.ModuleList([
            nn.Linear(dim, d_model) for dim in modality_dims
        ])

        # Positional encoding (æ¨¡æ€é¡ºåºç¼–ç )
        self.pos_encoding = nn.Parameter(torch.randn(1, 4, d_model))

        # Transformer Encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=64,
            dropout=0.2,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)

        # Classification head
        self.classifier = nn.Sequential(
            nn.Linear(d_model * 4, 32),  # æ‹¼æ¥4ä¸ªæ¨¡æ€çš„è¾“å‡º
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 2)
        )

    def forward(self, x_modalities):
        """
        x_modalities: [batch, 4, varying_dims] åˆ—è¡¨
        """
        # åµŒå…¥æ¯ä¸ªæ¨¡æ€
        tokens = []
        for i, (embed, x_mod) in enumerate(zip(self.modality_embeddings, x_modalities)):
            token = embed(x_mod)  # [batch, d_model]
            tokens.append(token)

        # [batch, 4, d_model]
        tokens = torch.stack(tokens, dim=1)
        tokens = tokens + self.pos_encoding

        # Transformer
        attended = self.transformer(tokens)  # [batch, 4, d_model]

        # æ‹¼æ¥å¹¶åˆ†ç±»
        pooled = attended.flatten(1)  # [batch, 4*d_model]
        logits = self.classifier(pooled)

        # è¿”å›logitså’Œæ³¨æ„åŠ›æƒé‡ï¼ˆç”¨äºå¯è§£é‡Šæ€§ï¼‰
        return logits, attended

    def get_attention_weights(self):
        """æå–è·¨æ¨¡æ€æ³¨æ„åŠ›æƒé‡"""
        # ä»transformerå±‚æå–attention map
        return self.transformer.layers[0].self_attn.attention_weights
```

#### 5D.3 å¯è§£é‡Šæ€§åˆ†æ

**æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–ï¼š**
- è®¡ç®—æ¯ä¸ªæ¨¡æ€å¯¹é¢„æµ‹çš„è´¡çŒ®åº¦
- ç¤ºä¾‹ï¼šGPSæ¨¡æ€æƒé‡=0.4ï¼ŒApp=0.3ï¼Œé€šä¿¡=0.2ï¼Œæ´»åŠ¨=0.1
- å‘ç°ï¼šå“ªä¸ªæ¨¡æ€å¯¹æŠ‘éƒé¢„æµ‹æœ€é‡è¦ï¼Ÿ

**æ–°å»ºæ–‡ä»¶ï¼š**
- `scripts/11_train_transformer.py`
- `notebooks/07_transformer_analysis.ipynb`

**è¾“å‡ºï¼š**
- `results/models/multimodal_transformer.pth`
- `results/figures/modality_attention_heatmap.png`
- `results/figures/transformer_feature_importance.png`

---

### Phase 6: æ¨¡å‹å¯¹æ¯”ä¸è¯„ä¼°

**ç›®æ ‡ï¼š** ç³»ç»Ÿæ¯”è¾ƒæ‰€æœ‰æ¨¡å‹æ€§èƒ½

#### 6.1 ç»Ÿä¸€è¯„ä¼°æ¡†æ¶

**æ–°å»ºæ–‡ä»¶ï¼š`scripts/12_evaluate_all_models.py`**

```python
# è¯„ä¼°æ‰€æœ‰7ä¸ªæ¨¡å‹
models = {
    'Logistic Regression': baseline_lr,
    'Random Forest': baseline_rf,
    'XGBoost': baseline_xgb,
    'VAE (Anomaly)': vae_model,
    'GNN': gnn_model,
    'Contrastive': contrastive_model,
    'Transformer': transformer_model
}

# ç»Ÿä¸€æŒ‡æ ‡
metrics = [
    'AUC-ROC',
    'PR-AUC',  # æ›´é€‚åˆä¸å¹³è¡¡æ•°æ®
    'Sensitivity (Recall)',
    'Specificity',
    'F1-Score',
    'Permutation Test p-value'
]

# ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
results_df = pd.DataFrame(...)
results_df.to_csv('results/tables/model_comparison.csv')
```

#### 6.2 å¯è§†åŒ–å¯¹æ¯”

**æ–°å»ºæ–‡ä»¶ï¼š`src/visualization/compare_models.py`**

```python
def plot_all_roc_curves(models, X_test, y_test):
    """ç»˜åˆ¶æ‰€æœ‰æ¨¡å‹çš„ROCæ›²çº¿åœ¨åŒä¸€å›¾ä¸Š"""
    plt.figure(figsize=(10, 8))
    for name, model in models.items():
        y_pred_proba = model.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        auc = roc_auc_score(y_test, y_pred_proba)
        plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})')
    plt.legend()
    plt.savefig('results/figures/all_models_roc_comparison.png')
```

**è¾“å‡ºï¼š**
- `results/figures/all_models_roc_comparison.png`
- `results/figures/model_performance_barplot.png`
- `results/tables/model_comparison.csv`

---

### Phase 7: å¯è§£é‡Šæ€§ä¸ç”Ÿç‰©æ ‡è®°å‘ç°

**ç›®æ ‡ï¼š** ä»æ¨¡å‹ä¸­æå–ä¸´åºŠå¯ç”¨çš„æ´å¯Ÿ

#### 7.1 Baselineæ¨¡å‹å¯è§£é‡Šæ€§

**SHAPåˆ†æï¼ˆå·²è§„åˆ’åœ¨åŸPhase 5ï¼‰ï¼š**

**æ–°å»ºæ–‡ä»¶ï¼š`src/interpretability/shap_analysis.py`**

```python
import shap

def explain_baseline_models(model, X_train, feature_names):
    """
    ä¸ºé€»è¾‘å›å½’ã€éšæœºæ£®æ—ã€XGBoostç”ŸæˆSHAPå€¼
    """
    explainer = shap.TreeExplainer(model)  # For RF/XGB
    shap_values = explainer.shap_values(X_train)

    # Summary plot
    shap.summary_plot(shap_values, X_train, feature_names=feature_names,
                      show=False)
    plt.savefig('results/figures/shap_summary.png', bbox_inches='tight')

    # Feature importance ranking
    feature_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': np.abs(shap_values).mean(0)
    }).sort_values('importance', ascending=False)

    return feature_importance
```

#### 7.2 æ·±åº¦å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§

**æ–°å»ºæ–‡ä»¶ï¼š`src/interpretability/dl_interpretability.py`**

```python
class DeepModelInterpreter:

    @staticmethod
    def vae_latent_space_analysis(vae, X, y):
        """
        åˆ†æVAEæ½œåœ¨ç©ºé—´ä¸­å“ªäº›ç»´åº¦åŒºåˆ†é˜³æ€§/é˜´æ€§
        """
        with torch.no_grad():
            z_mean, _ = vae.encode(X)

        # æ¯ä¸ªæ½œåœ¨ç»´åº¦çš„åˆ¤åˆ«åŠ›ï¼ˆt-testï¼‰
        from scipy.stats import ttest_ind
        p_values = []
        for dim in range(z_mean.shape[1]):
            pos = z_mean[y == 1, dim]
            neg = z_mean[y == 0, dim]
            _, p = ttest_ind(pos, neg)
            p_values.append(p)

        return p_values

    @staticmethod
    def gnn_attention_analysis(gnn, graph_data):
        """
        åˆ†æGNNæ³¨æ„åŠ›æƒé‡ï¼šå“ªäº›ç”¨æˆ·è¿æ¥é‡è¦
        """
        _, attention_weights = gnn.get_attention_weights()
        # å¯è§†åŒ–é«˜æ³¨æ„åŠ›è¾¹
        return attention_weights

    @staticmethod
    def transformer_modality_importance(transformer, X_modalities):
        """
        è®¡ç®—æ¯ä¸ªæ¨¡æ€çš„å¹³å‡æ³¨æ„åŠ›æƒé‡
        """
        with torch.no_grad():
            _, attended_tokens = transformer(X_modalities)
            # attended_tokens: [batch, 4, d_model]
            modality_norms = torch.norm(attended_tokens, dim=2).mean(0)
            # [4] - æ¯ä¸ªæ¨¡æ€çš„é‡è¦æ€§åˆ†æ•°

        modalities = ['GPS', 'App Usage', 'Communication', 'Activity']
        importance_df = pd.DataFrame({
            'Modality': modalities,
            'Importance': modality_norms.cpu().numpy()
        })
        return importance_df
```

#### 7.3 æ•°å­—ç”Ÿç‰©æ ‡è®°å‘ç°

**ç»¼åˆåˆ†ææŠ¥å‘Šï¼š**

**æ–°å»ºæ–‡ä»¶ï¼š`scripts/13_generate_biomarker_report.py`**

```python
# æ•´åˆæ‰€æœ‰æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§
biomarkers = {
    'Baseline (SHAP)': top_features_shap,
    'Transformer': top_modalities,
    'VAE': discriminative_latent_dims,
    'GNN': central_nodes_features
}

# ç”Ÿæˆä¸´åºŠè§£é‡Š
clinical_interpretation = {
    'location_variance_mean': 'GPSä½ç½®æ–¹å·® â†“ â†’ ç¤¾äº¤é€€ç¼©ï¼ˆSaeb 2015ï¼‰',
    'call_count_mean': 'é€šè¯é¢‘ç‡ â†“ â†’ ç¤¾äº¤å­¤ç«‹ï¼ˆFarhan 2016ï¼‰',
    'night_usage_ratio': 'å¤œé—´æ‰‹æœºä½¿ç”¨ â†‘ â†’ å¤±çœ /æ˜¼å¤œèŠ‚å¾‹ç´Šä¹±',
    'sedentary_days_ratio': 'ä¹…åå¤©æ•° â†‘ â†’ ç²¾ç¥è¿åŠ¨æ€§è¿Ÿæ»'
}

# è¾“å‡ºmarkdownæŠ¥å‘Š
report = generate_markdown_report(biomarkers, clinical_interpretation)
with open('results/digital_biomarkers_report.md', 'w') as f:
    f.write(report)
```

**è¾“å‡ºï¼š**
- `results/digital_biomarkers_report.md` - ä¸´åºŠå¯è¯»çš„ç”Ÿç‰©æ ‡è®°æŠ¥å‘Š
- `results/figures/biomarker_ranking.png` - è·¨æ¨¡å‹ä¸€è‡´æ€§æ’å
- `results/tables/top_biomarkers.csv`

---

## æ–‡ä»¶ç»“æ„æ€»è§ˆ

```
multimodal-depression-detection/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ model_configs.yaml              [æ–°å»º] è¶…å‚æ•°é…ç½®
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baseline.py                 [æ–°å»º] ä¼ ç»ŸMLæ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ evaluation.py               [æ–°å»º] è¯„ä¼°å·¥å…·
â”‚   â”‚   â”œâ”€â”€ pytorch_base.py             [æ–°å»º] PyTorchåŸºç±»
â”‚   â”‚   â”œâ”€â”€ vae_model.py                [æ–°å»º] VAE
â”‚   â”‚   â”œâ”€â”€ gnn_model.py                [æ–°å»º] GNN
â”‚   â”‚   â”œâ”€â”€ contrastive_model.py        [æ–°å»º] å¯¹æ¯”å­¦ä¹ 
â”‚   â”‚   â””â”€â”€ multimodal_transformer.py   [æ–°å»º] Transformer
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ graph_builder.py            [æ–°å»º] å›¾æ„å»º
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ data_loader.py              [æ–°å»º] æ•°æ®åŠ è½½
â”‚   â”‚   â”œâ”€â”€ pytorch_utils.py            [æ–°å»º] PyTorchå·¥å…·
â”‚   â”‚   â””â”€â”€ augmentation.py             [æ–°å»º] æ•°æ®å¢å¼º
â”‚   â”œâ”€â”€ interpretability/
â”‚   â”‚   â”œâ”€â”€ shap_analysis.py            [æ–°å»º] SHAP
â”‚   â”‚   â””â”€â”€ dl_interpretability.py      [æ–°å»º] æ·±åº¦å­¦ä¹ å¯è§£é‡Šæ€§
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ compare_models.py           [æ–°å»º] æ¨¡å‹å¯¹æ¯”å¯è§†åŒ–
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 07_train_baseline.py            [æ–°å»º]
â”‚   â”œâ”€â”€ 08_train_vae.py                 [æ–°å»º]
â”‚   â”œâ”€â”€ 09_train_gnn.py                 [æ–°å»º]
â”‚   â”œâ”€â”€ 10_train_contrastive.py         [æ–°å»º]
â”‚   â”œâ”€â”€ 11_train_transformer.py         [æ–°å»º]
â”‚   â”œâ”€â”€ 12_evaluate_all_models.py       [æ–°å»º]
â”‚   â””â”€â”€ 13_generate_biomarker_report.py [æ–°å»º]
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 03_baseline_modeling.ipynb      [æ–°å»º]
â”‚   â”œâ”€â”€ 04_vae_analysis.ipynb           [æ–°å»º]
â”‚   â”œâ”€â”€ 05_gnn_analysis.ipynb           [æ–°å»º]
â”‚   â”œâ”€â”€ 06_contrastive_analysis.ipynb   [æ–°å»º]
â”‚   â””â”€â”€ 07_transformer_analysis.ipynb   [æ–°å»º]
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ models/                         [PyTorch .pth + sklearn .pkl]
â”‚   â”œâ”€â”€ metrics/                        [JSONæ€§èƒ½æŒ‡æ ‡]
â”‚   â”œâ”€â”€ figures/                        [æ‰€æœ‰å¯è§†åŒ–]
â”‚   â”œâ”€â”€ tables/                         [å¯¹æ¯”è¡¨æ ¼]
â”‚   â””â”€â”€ digital_biomarkers_report.md    [æ–°å»º] æœ€ç»ˆæŠ¥å‘Š
â””â”€â”€ requirements.txt                     [æ›´æ–°] æ·»åŠ PyTorchä¾èµ–
```

---

## å®æ–½é¡ºåºå»ºè®®

### ç¬¬ä¸€å‘¨ï¼šBaseline + åŸºç¡€è®¾æ–½
1. æ›´æ–°requirements.txtï¼Œå®‰è£…PyTorchï¼ˆæ”¯æŒMPSï¼‰
2. å®ç°`src/models/baseline.py`å’Œ`src/models/evaluation.py`
3. è¿è¡Œ`scripts/07_train_baseline.py`
4. å»ºç«‹PyTorchåŸºç¡€è®¾æ–½ï¼ˆ`pytorch_base.py`, `pytorch_utils.py`ï¼‰
5. åˆ›å»º`configs/model_configs.yaml`

### ç¬¬äºŒå‘¨ï¼šVAE + GNN
6. å®ç°VAEæ¨¡å‹ï¼ˆ`vae_model.py`ï¼‰
7. è®­ç»ƒVAEå¹¶ç”Ÿæˆåˆæˆæ ·æœ¬
8. æ„å»ºç”¨æˆ·ç›¸ä¼¼æ€§å›¾ï¼ˆ`graph_builder.py`ï¼‰
9. å®ç°GNNæ¨¡å‹ï¼ˆ`gnn_model.py`ï¼‰
10. è®­ç»ƒGNNå¹¶å¯è§†åŒ–èŠ‚ç‚¹åµŒå…¥

### ç¬¬ä¸‰å‘¨ï¼šå¯¹æ¯”å­¦ä¹  + Transformer
11. å®ç°æ•°æ®å¢å¼ºç­–ç•¥ï¼ˆ`augmentation.py`ï¼‰
12. å®ç°å¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼ˆ`contrastive_model.py`ï¼‰
13. å®ç°å¤šæ¨¡æ€Transformerï¼ˆ`multimodal_transformer.py`ï¼‰
14. è®­ç»ƒä¸¤ä¸ªæ¨¡å‹å¹¶åˆ†ææ³¨æ„åŠ›æƒé‡

### ç¬¬å››å‘¨ï¼šè¯„ä¼° + å¯è§£é‡Šæ€§
15. è¿è¡Œ`scripts/12_evaluate_all_models.py`å¯¹æ¯”æ‰€æœ‰æ¨¡å‹
16. SHAPåˆ†æï¼ˆbaselineï¼‰
17. æ·±åº¦å­¦ä¹ å¯è§£é‡Šæ€§åˆ†æ
18. ç”Ÿæˆæ•°å­—ç”Ÿç‰©æ ‡è®°æŠ¥å‘Š
19. åˆ¶ä½œpublication-quality figures

---

## å…³é”®æŠ€æœ¯å†³ç­–

### 1. å¤„ç†å°æ ·æœ¬ï¼ˆn=46ï¼‰çš„ç­–ç•¥

**é—®é¢˜ï¼š** æ·±åº¦å­¦ä¹ é€šå¸¸éœ€è¦å¤§é‡æ•°æ®ï¼Œ46ä¸ªæ ·æœ¬å®¹æ˜“è¿‡æ‹Ÿåˆ

**è§£å†³æ–¹æ¡ˆï¼š**
- âœ… ä½¿ç”¨å°å‹ç½‘ç»œï¼ˆå‚æ•°é‡ < 1000ï¼‰
- âœ… å¼ºæ­£åˆ™åŒ–ï¼ˆDropout 0.2-0.3, Weight Decay 0.01ï¼‰
- âœ… Early stoppingï¼ˆpatience=20ï¼‰
- âœ… Leave-One-Out CVè€Œék-foldï¼ˆæœ€å¤§åŒ–è®­ç»ƒæ•°æ®ï¼‰
- âœ… æ•°æ®å¢å¼ºï¼ˆVAEåˆæˆæ ·æœ¬ã€å¯¹æ¯”å­¦ä¹ augmentationï¼‰
- âœ… è¿ç§»å­¦ä¹ æ€æƒ³ï¼ˆå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ â†’ å¾®è°ƒåˆ†ç±»å™¨ï¼‰
- âœ… å›¾ç»“æ„åˆ©ç”¨ç”¨æˆ·ç›¸ä¼¼æ€§ï¼ˆGNNåŠç›‘ç£å­¦ä¹ ï¼‰

### 2. å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆ4 vs 42ï¼‰çš„ç­–ç•¥

**é—®é¢˜ï¼š** åªæœ‰4ä¸ªé˜³æ€§æ ·æœ¬ï¼Œæ¨¡å‹å€¾å‘äºé¢„æµ‹æ‰€æœ‰æ ·æœ¬ä¸ºé˜´æ€§

**è§£å†³æ–¹æ¡ˆï¼š**
- âœ… Baseline: `class_weight='balanced'`ï¼ˆscikit-learnï¼‰
- âœ… XGBoost: `scale_pos_weight=10.5`
- âœ… PyTorch: `WeightedRandomSampler`æˆ–focal loss
- âœ… VAEæ•°æ®å¢å¼ºï¼šç”Ÿæˆ20-30ä¸ªåˆæˆé˜³æ€§æ ·æœ¬
- âœ… è¯„ä¼°æŒ‡æ ‡ï¼šä¼˜å…ˆçœ‹PR-AUCã€Sensitivityï¼ˆè€ŒéAccuracyï¼‰
- âœ… é˜ˆå€¼è°ƒæ•´ï¼šä¼˜åŒ–Sensitivityâ‰¥0.80ï¼ˆä¸´åºŠè¦æ±‚ï¼‰

### 3. MPSåŠ é€Ÿé…ç½®ï¼ˆMacBookï¼‰

**Apple Siliconä¼˜åŒ–ï¼š**
```python
# åœ¨æ‰€æœ‰PyTorchè„šæœ¬å¼€å¤´æ·»åŠ 
import torch

# è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("Using Apple Silicon MPS")
elif torch.cuda.is_available():
    device = torch.device("cuda")
else:
    device = torch.device("cpu")

# æ¨¡å‹å’Œæ•°æ®ç§»åŠ¨åˆ°MPS
model = model.to(device)
data = data.to(device)
```

**æ³¨æ„äº‹é¡¹ï¼š**
- MPSåœ¨å°æ‰¹é‡ï¼ˆbatch_size < 32ï¼‰æ—¶åŠ é€Ÿä¸æ˜æ˜¾
- æŸäº›æ“ä½œï¼ˆå¦‚GNNçš„ç¨€ç–çŸ©é˜µï¼‰å¯èƒ½ä¸æ”¯æŒMPSï¼Œéœ€é™çº§åˆ°CPU
- å»ºè®®åœ¨`pytorch_utils.py`ä¸­å°è£…è®¾å¤‡é€‰æ‹©é€»è¾‘

### 4. è¶…å‚æ•°æœç´¢ç­–ç•¥

**é—®é¢˜ï¼š** ç½‘æ ¼æœç´¢æˆæœ¬é«˜ï¼Œä¸”46ä¸ªæ ·æœ¬ä¸è¶³ä»¥åˆ†å‡ºéªŒè¯é›†

**è§£å†³æ–¹æ¡ˆï¼š**
- âœ… Baseline: ä½¿ç”¨æ–‡çŒ®æ¨èå€¼ï¼ˆSaeb 2015, Farhan 2016ï¼‰
- âœ… æ·±åº¦å­¦ä¹ : å…ˆç”¨ç»éªŒå€¼ï¼ˆconfigs/model_configs.yamlï¼‰
- âœ… å¦‚éœ€è°ƒä¼˜: ä½¿ç”¨åµŒå¥—CVï¼ˆå¤–å±‚LOO-CVï¼Œå†…å±‚5-foldï¼‰
- âœ… ä¼˜å…ˆè°ƒæ•´æ­£åˆ™åŒ–å‚æ•°ï¼ˆdropout, weight_decayï¼‰è€Œéç½‘ç»œç»“æ„

---

## é¢„æœŸç»“æœ

### æ€§èƒ½é¢„æœŸï¼ˆåŸºäºæ–‡çŒ®ï¼‰

| æ¨¡å‹ç±»å‹ | é¢„æœŸAUC-ROC | ä¼˜åŠ¿ | é£é™© |
|---------|------------|------|------|
| Logistic Regression | 0.60-0.70 | å¯è§£é‡Šæ€§å¼ºï¼Œbaseline | ç‰¹å¾çº¿æ€§å‡è®¾ |
| Random Forest | 0.65-0.75 | éçº¿æ€§ï¼Œé²æ£’ | è¿‡æ‹Ÿåˆé£é™© |
| XGBoost | 0.65-0.75 | SOTAä¼ ç»ŸML | éœ€ä»”ç»†è°ƒå‚ |
| VAE | 0.55-0.65 (å¼‚å¸¸æ£€æµ‹) | ç”Ÿæˆåˆæˆæ ·æœ¬ | é‡æ„è¯¯å·®åˆ¤åˆ«åŠ›å¼± |
| GNN | 0.70-0.80 | åˆ©ç”¨ç”¨æˆ·ç›¸ä¼¼æ€§ | å›¾ç»“æ„è´¨é‡ä¾èµ– |
| Contrastive | 0.65-0.75 | å°æ ·æœ¬å‹å¥½ | å¢å¼ºç­–ç•¥è®¾è®¡éš¾ |
| Transformer | 0.70-0.80 | è·¨æ¨¡æ€äº¤äº’ | å‚æ•°é‡å¤§æ˜“è¿‡æ‹Ÿåˆ |

**æ³¨æ„ï¼š** n=46çš„å°æ ·æœ¬ä¼šå¯¼è‡´AUCç½®ä¿¡åŒºé—´å¾ˆå®½ï¼ˆÂ±0.10ï¼‰ï¼Œéœ€è¿›è¡Œ1000æ¬¡permutation testéªŒè¯ç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆp<0.05ï¼‰ã€‚

### ç§‘ç ”è´¡çŒ®ï¼ˆå³ä½¿æ€§èƒ½ä¸€èˆ¬ï¼‰

1. **æ–¹æ³•å­¦åˆ›æ–°ï¼š** é¦–æ¬¡ç³»ç»Ÿå¯¹æ¯”ä¼ ç»ŸML vs æ·±åº¦å­¦ä¹ åœ¨å°æ ·æœ¬å¤šæ¨¡æ€æŠ‘éƒæ£€æµ‹ä»»åŠ¡
2. **è¡¨ç¤ºå­¦ä¹ ï¼š** VAE/å¯¹æ¯”å­¦ä¹ çš„æ½œåœ¨ç©ºé—´å¯è§†åŒ–æœ¬èº«æœ‰å­¦æœ¯ä»·å€¼
3. **å¯è§£é‡Šæ€§ï¼š** Transformeræ³¨æ„åŠ›æƒé‡æ­ç¤ºGPS vs é€šä¿¡ vs æ´»åŠ¨çš„ç›¸å¯¹é‡è¦æ€§
4. **æ•°æ®å¢å¼ºï¼š** VAEåˆæˆæ ·æœ¬ä¸ºæœªæ¥ç±»ä¼¼å°æ ·æœ¬ç ”ç©¶æä¾›æ–¹æ³•è®º
5. **ä¸´åºŠç¿»è¯‘ï¼š** SHAP + æ³¨æ„åŠ›æƒé‡ â†’ å¯æ“ä½œçš„æ•°å­—ç”Ÿç‰©æ ‡è®°

---

## é£é™©ç¼“è§£

### é£é™©1: æ‰€æœ‰æ¨¡å‹æ€§èƒ½æ¥è¿‘éšæœºçŒœæµ‹ï¼ˆAUC~0.50ï¼‰

**å¯èƒ½åŸå› ï¼š**
- 44ä¸ªç‰¹å¾ä¸åŒ…å«é¢„æµ‹ä¿¡å·
- 4ä¸ªé˜³æ€§æ ·æœ¬ä¸è¶³ä»¥å­¦ä¹ æ¨¡å¼

**åº”å¯¹æªæ–½ï¼š**
- æ£€æŸ¥ç‰¹å¾åˆ†å¸ƒï¼šé˜³æ€§vsé˜´æ€§æ˜¯å¦æœ‰æ˜¾è‘—å·®å¼‚ï¼ˆt-testï¼‰
- ä½¿ç”¨permutation testï¼šå³ä½¿AUCä½ï¼Œä¹ŸéªŒè¯æ˜¯å¦æ˜¾è‘—ä¼˜äºéšæœº
- é™çº§ç ”ç©¶é—®é¢˜ï¼šä»"é¢„æµ‹"æ”¹ä¸º"æ¢ç´¢æ€§åˆ†æ"
- å…³æ³¨ç‰¹å¾è¡¨ç¤ºè´¨é‡è€Œéåˆ†ç±»æ€§èƒ½ï¼ˆVAEæ½œåœ¨ç©ºé—´ã€GNNåµŒå…¥ï¼‰

### é£é™©2: æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸¥é‡è¿‡æ‹Ÿåˆ

**ç—‡çŠ¶ï¼š** è®­ç»ƒAUC=1.0ï¼Œæµ‹è¯•AUC<0.5

**åº”å¯¹æªæ–½ï¼š**
- å‡å°æ¨¡å‹ï¼ˆhidden_dimä»32é™åˆ°16ï¼‰
- å¢å¼ºæ­£åˆ™åŒ–ï¼ˆdropoutä»0.2å‡åˆ°0.5ï¼‰
- ä½¿ç”¨æ›´ç®€å•çš„baselineï¼ˆçº¿æ€§æ¨¡å‹ï¼‰
- å°è¯•transfer learningï¼ˆä½¿ç”¨å¤§è§„æ¨¡å¥åº·æ•°æ®é¢„è®­ç»ƒï¼‰

### é£é™©3: MPSåŠ é€Ÿä¸å·¥ä½œæˆ–æŠ¥é”™

**åº”å¯¹æªæ–½ï¼š**
- é™çº§åˆ°CPUï¼ˆbatch_sizeå°æ—¶é€Ÿåº¦å·®å¼‚ä¸å¤§ï¼‰
- æ£€æŸ¥PyTorchç‰ˆæœ¬ï¼ˆéœ€>=2.0ï¼‰
- æŸäº›æ“ä½œæ‰‹åŠ¨æŒ‡å®š`.to("cpu")`ï¼ˆå¦‚ç¨€ç–çŸ©é˜µï¼‰

---

## æ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹å®æ–½å‰ç¡®è®¤ï¼š

- [ ] mambaç¯å¢ƒ`qbio`å·²æ¿€æ´»
- [ ] ç¡®è®¤`data/processed/features/combined_features.parquet`å­˜åœ¨ï¼ˆ46Ã—44ï¼‰
- [ ] ç¡®è®¤`data/processed/labels/item9_labels_pre.csv`å­˜åœ¨
- [ ] åˆ›å»º`configs/`æ–‡ä»¶å¤¹
- [ ] æ›´æ–°`requirements.txt`æ·»åŠ PyTorch
- [ ] æµ‹è¯•MPSæ˜¯å¦å¯ç”¨ï¼š`python -c "import torch; print(torch.backends.mps.is_available())"`
- [ ] é˜…è¯»Saeb et al. (2015)å’ŒFarhan et al. (2016)äº†è§£é¢„æœŸç‰¹å¾é‡è¦æ€§

---

## æœ€ç»ˆäº¤ä»˜ç‰©

### ä»£ç 
- 20+ä¸ªæ–°Pythonæ¨¡å—ï¼ˆæ¨¡å‹ã€å·¥å…·ã€å¯è§†åŒ–ï¼‰
- 7ä¸ªè®­ç»ƒè„šæœ¬
- 5ä¸ªJupyter notebooks

### ç»“æœ
- 7ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆ.pkl + .pthï¼‰
- 15+ä¸ªå¯è§†åŒ–å›¾è¡¨ï¼ˆROCã€confusion matrixã€attentionã€t-SNEç­‰ï¼‰
- æ¨¡å‹å¯¹æ¯”è¡¨æ ¼ï¼ˆCSVï¼‰
- æ•°å­—ç”Ÿç‰©æ ‡è®°æŠ¥å‘Šï¼ˆMarkdownï¼‰

### æ–‡æ¡£
- æ›´æ–°README.mdæ·»åŠ Phase 3-7è¯´æ˜
- æ¯ä¸ªè„šæœ¬çš„docstringå’Œä½¿ç”¨ç¤ºä¾‹
- `digital_biomarkers_report.md`åŒ…å«ä¸´åºŠè§£é‡Š

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç”¨æˆ·ç¡®è®¤è®¡åˆ’** - æ˜¯å¦åŒæ„ä¸Šè¿°æ–¹æ¡ˆï¼Ÿæœ‰è°ƒæ•´éœ€æ±‚å—ï¼Ÿ
2. **ç¯å¢ƒå‡†å¤‡** - å®‰è£…PyTorchå’Œç›¸å…³ä¾èµ–
3. **å¼€å§‹Phase 3** - å…ˆå®ç°baselineæ¨¡å‹éªŒè¯æ•°æ®è´¨é‡
4. **è¿­ä»£å¼€å‘** - æŒ‰å‘¨å®æ–½VAE â†’ GNN â†’ å¯¹æ¯”å­¦ä¹  â†’ Transformer

å‡†å¤‡å¥½åæˆ‘ä»¬å¼€å§‹å®æ–½ï¼ğŸš€
