# Model Configuration File
# Hyperparameters for all models in the multimodal depression detection project

# Common settings across all models
common:
  batch_size: 16  # Small batch size to avoid overfitting with n=46
  learning_rate: 0.001
  weight_decay: 0.01  # L2 regularization
  max_epochs: 200
  early_stopping_patience: 20
  random_seed: 42
  test_size: 0.2  # For train/test split
  cv_folds: 5  # For stratified k-fold CV

# Baseline Models (scikit-learn)
baseline:
  logistic_regression:
    C: 1.0  # Inverse of L2 regularization strength
    penalty: 'l2'
    solver: 'lbfgs'
    max_iter: 1000
    class_weight: 'balanced'  # Handle class imbalance (4 vs 42)

  random_forest:
    n_estimators: 500
    max_depth: 3  # Shallow trees to prevent overfitting
    min_samples_split: 5
    min_samples_leaf: 2
    class_weight: 'balanced'
    random_state: 42
    n_jobs: -1

  xgboost:
    n_estimators: 300
    max_depth: 3
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    scale_pos_weight: 10.5  # Handle 10.5:1 class imbalance
    random_state: 42
    n_jobs: -1

# Variational Autoencoder (VAE)
vae:
  input_dim: 44
  latent_dim: 8  # Low-dimensional latent space
  hidden_dims: [32, 16]  # Encoder/Decoder hidden layers
  beta: 1.0  # Beta-VAE: weight for KL divergence
  dropout: 0.2
  batch_norm: true
  learning_rate: 0.001
  weight_decay: 0.01

  # For data augmentation
  n_synthetic_samples: 25  # Generate 25 synthetic positive samples (from 4 real)

# Graph Neural Network (GNN)
gnn:
  in_channels: 44
  hidden_channels: 16  # Small to avoid overfitting
  num_layers: 2
  heads: 4  # For GAT (Graph Attention Network)
  dropout: 0.3
  learning_rate: 0.001
  weight_decay: 0.01

  # Graph construction
  k_neighbors: 5  # K-NN graph construction
  similarity_metric: 'cosine'  # For edge weights

# Contrastive Learning
contrastive:
  input_dim: 44
  encoder_dims: [64, 32]  # Encoder architecture
  projection_dim: 32  # Projection head output
  temperature: 0.5  # NT-Xent loss temperature
  dropout: 0.2
  learning_rate: 0.001
  weight_decay: 0.01

  # Data augmentation
  augmentation_strength: 0.2
  noise_std: 0.1
  mixup_alpha: 0.2
  cutout_prob: 0.2

# Multimodal Transformer
transformer:
  modality_dims: [11, 10, 11, 12]  # GPS, App, Communication, Activity
  d_model: 16  # Model dimension (keep small for n=46)
  nhead: 4  # Number of attention heads
  num_layers: 2  # Transformer encoder layers
  dim_feedforward: 64
  dropout: 0.2
  learning_rate: 0.001
  weight_decay: 0.01

# Evaluation settings
evaluation:
  # Metrics for imbalanced classification
  metrics:
    - 'roc_auc'
    - 'pr_auc'  # Precision-Recall AUC (better for imbalanced data)
    - 'sensitivity'  # Recall for positive class
    - 'specificity'
    - 'f1_score'
    - 'balanced_accuracy'

  # Cross-validation
  cv_strategy: 'stratified'  # 'stratified' or 'loo' (Leave-One-Out)
  n_cv_folds: 5

  # Permutation test for statistical significance
  permutation_test:
    n_permutations: 1000
    alpha: 0.05

  # Classification threshold optimization
  optimize_threshold_for: 'sensitivity'  # Optimize for sensitivity â‰¥ 0.80
  target_sensitivity: 0.80

# Feature settings
features:
  # Feature groups (indices in combined_features.parquet)
  gps_indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # 11 features
  app_indices: [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]  # 10 features
  communication_indices: [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]  # 11 features
  activity_indices: [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]  # 12 features

  # Feature scaling
  scaling_method: 'standard'  # 'standard', 'minmax', or 'robust'

  # Feature selection (optional)
  feature_selection:
    enabled: false
    method: 'mutual_info'  # 'mutual_info', 'f_classif', or 'shap'
    n_features: 20

# Paths
paths:
  data:
    features: 'data/processed/features/combined_features.parquet'
    labels: 'data/processed/labels/item9_labels_pre.csv'
    feature_summary: 'data/processed/features/feature_summary.csv'

  results:
    models: 'results/models'
    metrics: 'results/metrics'
    figures: 'results/figures'
    tables: 'results/tables'

  logs:
    training: 'logs/training'
    evaluation: 'logs/evaluation'

# Device settings
device:
  # Automatically detect: MPS (Apple Silicon) > CUDA > CPU
  auto_detect: true
  # Or manually specify: 'mps', 'cuda', or 'cpu'
  force_device: null
