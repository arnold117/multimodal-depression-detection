{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPS Mobility Features - Exploration & Validation\n",
    "\n",
    "This notebook explores the GPS mobility features extracted in Phase 2.\n",
    "\n",
    "## Features Extracted\n",
    "Following Saeb et al. (2015):\n",
    "1. **Location variance** (log-transformed) - strongest depression predictor\n",
    "2. **Distance traveled** (mean/std)\n",
    "3. **Radius of gyration** (spatial spread)\n",
    "4. **Home stay ratio** (social withdrawal proxy)\n",
    "5. **Location diversity** (number of significant locations via DBSCAN)\n",
    "6. **Movement entropy** (predictability of hourly patterns)\n",
    "7. **Variability metrics** (CV for distance and radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPS features\n",
    "gps_features = pd.read_parquet('../data/processed/features/gps_mobility_features.parquet')\n",
    "\n",
    "# Load PHQ-9 labels\n",
    "item9_labels = pd.read_csv('../data/processed/labels/item9_labels_pre.csv')\n",
    "phq9_labels = pd.read_csv('../data/processed/labels/phq9_labels_pre.csv')\n",
    "\n",
    "# Merge with labels\n",
    "df = gps_features.merge(item9_labels, on='uid', how='left')\n",
    "df = df.merge(phq9_labels[['uid', 'phq9_total', 'severity_category']], on='uid', how='left')\n",
    "\n",
    "print(f\"Total users with GPS features: {len(df)}\")\n",
    "print(f\"Users with suicidal ideation: {df['item9_binary'].sum()}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['item9_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns (exclude uid and metadata)\n",
    "feature_cols = [\n",
    "    'location_variance_mean', 'location_variance_std',\n",
    "    'distance_traveled_mean', 'distance_traveled_std', 'distance_traveled_cv',\n",
    "    'radius_of_gyration_mean', 'radius_gyration_cv',\n",
    "    'max_distance_from_home', 'home_stay_ratio',\n",
    "    'n_significant_locations', 'movement_entropy'\n",
    "]\n",
    "\n",
    "# Summary statistics\n",
    "df[feature_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per feature:\")\n",
    "print(df[feature_cols].isnull().sum())\n",
    "\n",
    "# Check data coverage\n",
    "print(\"\\nGPS data coverage:\")\n",
    "print(f\"Mean valid days: {df['gps_valid_days'].mean():.1f} Â± {df['gps_valid_days'].std():.1f}\")\n",
    "print(f\"Min: {df['gps_valid_days'].min():.0f}, Max: {df['gps_valid_days'].max():.0f}\")\n",
    "print(f\"Mean points per day: {df['gps_points_per_day'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions by Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key features to visualize\n",
    "key_features = [\n",
    "    'location_variance_mean',\n",
    "    'distance_traveled_mean',\n",
    "    'home_stay_ratio',\n",
    "    'n_significant_locations'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Violin plot by outcome\n",
    "    sns.violinplot(data=df, x='item9_binary', y=feature, ax=ax)\n",
    "    ax.set_xlabel('Suicidal Ideation (0=No, 1=Yes)')\n",
    "    ax.set_title(f'{feature}\\nby PHQ-9 Item #9')\n",
    "    \n",
    "    # Add sample sizes\n",
    "    n0 = (df['item9_binary'] == 0).sum()\n",
    "    n1 = (df['item9_binary'] == 1).sum()\n",
    "    ax.text(0, ax.get_ylim()[1], f'n={n0}', ha='center', va='bottom')\n",
    "    ax.text(1, ax.get_ylim()[1], f'n={n1}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "corr_matrix = df[feature_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1)\n",
    "plt.title('GPS Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated pairs (|r| > 0.9)\n",
    "high_corr = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            high_corr.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "if high_corr:\n",
    "    print(\"\\nHighly correlated features (|r| > 0.9):\")\n",
    "    for f1, f2, r in high_corr:\n",
    "        print(f\"  {f1} <-> {f2}: r={r:.3f}\")\n",
    "else:\n",
    "    print(\"\\nNo highly correlated feature pairs (|r| > 0.9)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Association with Outcome\n",
    "\n",
    "Test association between each GPS feature and suicidal ideation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Perform Mann-Whitney U test for each feature\n",
    "results = []\n",
    "\n",
    "for feature in feature_cols:\n",
    "    # Split by outcome\n",
    "    group0 = df[df['item9_binary'] == 0][feature].dropna()\n",
    "    group1 = df[df['item9_binary'] == 1][feature].dropna()\n",
    "    \n",
    "    # Mann-Whitney U test (non-parametric)\n",
    "    if len(group0) > 0 and len(group1) > 0:\n",
    "        stat, p_value = mannwhitneyu(group0, group1, alternative='two-sided')\n",
    "        \n",
    "        results.append({\n",
    "            'feature': feature,\n",
    "            'mean_no_ideation': group0.mean(),\n",
    "            'mean_ideation': group1.mean(),\n",
    "            'difference': group1.mean() - group0.mean(),\n",
    "            'p_value': p_value\n",
    "        })\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('p_value')\n",
    "\n",
    "print(\"\\nUnivariate associations with suicidal ideation (Mann-Whitney U test):\")\n",
    "print(\"=\" * 80)\n",
    "for _, row in results_df.iterrows():\n",
    "    sig = \"***\" if row['p_value'] < 0.001 else \"**\" if row['p_value'] < 0.01 else \"*\" if row['p_value'] < 0.05 else \"\"\n",
    "    print(f\"{row['feature']:30s} p={row['p_value']:.4f} {sig:3s} | diff={row['difference']:7.3f}\")\n",
    "\n",
    "print(\"\\nNote: Small sample size (n=4 with ideation) limits statistical power.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings Summary\n",
    "\n",
    "Based on the analysis above, document:\n",
    "1. Features with strongest association to outcome\n",
    "2. Direction of effects (protective vs. risk)\n",
    "3. Data quality issues\n",
    "4. Recommendations for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by outcome\n",
    "print(\"GPS Features by Suicidal Ideation Status\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nNo ideation (n=42):\")\n",
    "print(df[df['item9_binary'] == 0][feature_cols].describe().loc[['mean', 'std']].T)\n",
    "print(\"\\nWith ideation (n=4):\")\n",
    "print(df[df['item9_binary'] == 1][feature_cols].describe().loc[['mean', 'std']].T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
